{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('vsenv': conda)",
   "display_name": "Python 3.8.5 64-bit ('vsenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1ee30a202add5215adcbb767012aec8477a9c484e522cef3494d0f72d70b8c03"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/user/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient('localhost',27017)\n",
    "db = client.db\n",
    "threads = db.threads\n",
    "companies = db.companylist\n",
    "matches = db.matches\n",
    "chunks = db.chunks\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "df = pd.DataFrame.from_records(threads.find({'Label':{'$ne': 0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.9077:bullish\n",
      "-0.7453:bullish\n",
      "-0.4522:bullish\n",
      "-0.9222:bullish\n",
      "0.9274:bearish\n",
      "0.8258:bearish\n",
      "0.1027:bearish\n",
      "-0.6037:bullish\n",
      "-0.9495:bullish\n",
      "0.8022:bearish\n",
      "-0.5267:bullish\n",
      "-0.5994:bullish\n",
      "0.3716:bearish\n",
      "0.8689:bearish\n",
      "-0.743:bullish\n",
      "0.4791:bearish\n",
      "-0.608:bullish\n",
      "0.2263:bearish\n",
      "-0.8371:bullish\n",
      "-0.8185:bullish\n",
      "0.6326:bearish\n",
      "0.9801:bearish\n",
      "-0.0874:bullish\n",
      "-0.953:bullish\n",
      "-0.25:bullish\n",
      "-0.5574:bullish\n",
      "0.5978:bearish\n",
      "0.9976:bearish\n",
      "-0.8658:bullish\n",
      "-0.4246:bullish\n",
      "-0.9578:bullish\n",
      "-0.3182:bullish\n",
      "-0.1027:bullish\n",
      "-0.5829:bullish\n",
      "-0.2313:bullish\n",
      "-0.8578:bullish\n",
      "0.7506:bearish\n",
      "0.7063:bearish\n",
      "-0.5789:bullish\n",
      "-0.4939:bullish\n",
      "0.8266:bearish\n",
      "-0.3533:bullish\n",
      "-0.4767:bullish\n",
      "-0.3249:bullish\n",
      "-0.1927:bullish\n",
      "0.4404:bearish\n",
      "0.323:bearish\n",
      "-0.7814:bullish\n",
      "0.296:bearish\n",
      "0.9917:bearish\n",
      "-0.5106:bullish\n",
      "-0.599:bullish\n",
      "0.8943:bearish\n",
      "0.8957:bearish\n",
      "-0.6369:bullish\n",
      "0.9042:bearish\n",
      "-0.5106:bullish\n",
      "0.8236:bearish\n",
      "0.9208:bearish\n",
      "-0.1027:bullish\n",
      "0.6739:bearish\n",
      "0.9169:bearish\n",
      "-0.3972:bullish\n",
      "-0.1655:bullish\n",
      "0.9617:bearish\n",
      "0.9825:bearish\n",
      "0.8656:bearish\n",
      "0.9984:bearish\n",
      "-0.0891:bullish\n",
      "0.9245:bearish\n",
      "0.2263:bearish\n",
      "-0.7184:bullish\n",
      "-0.128:bullish\n",
      "0.7906:bearish\n",
      "0.5766:bearish\n",
      "0.2103:bearish\n",
      "0.5789:bearish\n",
      "-0.0772:bullish\n",
      "0.7646:bearish\n",
      "-0.657:bullish\n",
      "0.9724:bearish\n",
      "-0.2429:bullish\n",
      "0.4824:bearish\n",
      "-0.1027:bullish\n",
      "0.7964:bearish\n",
      "0.9653:bearish\n",
      "-0.8537:bullish\n",
      "-0.1779:bullish\n",
      "-0.8856:bullish\n",
      "-0.2732:bullish\n",
      "-0.9059:bullish\n",
      "-0.1154:bullish\n",
      "0.8247:bearish\n",
      "-0.5346:bullish\n",
      "0.9442:bearish\n",
      "0.9635:bearish\n",
      "-0.128:bullish\n",
      "-0.4005:bullish\n",
      "0.5106:bearish\n",
      "-0.7115:bullish\n",
      "-0.4636:bullish\n",
      "-0.4309:bullish\n",
      "0.993:bearish\n",
      "0.3612:bearish\n",
      "-0.9873:bullish\n",
      "-0.7184:bullish\n",
      "-0.3551:bullish\n",
      "0.7213:bearish\n",
      "-0.2023:bullish\n",
      "-0.1531:bullish\n",
      "0.9122:bearish\n",
      "-0.8932:bullish\n",
      "-0.2356:bullish\n",
      "-0.9001:bullish\n",
      "-0.5216:bullish\n",
      "-0.5023:bullish\n",
      "0.2263:bearish\n",
      "-0.2744:bullish\n",
      "-0.4588:bullish\n",
      "-0.226:bullish\n",
      "-0.0516:bullish\n",
      "-0.8126:bullish\n",
      "-0.967:bullish\n",
      "0.3182:bearish\n",
      "-0.6597:bullish\n",
      "0.7227:bearish\n",
      "0.9569:bearish\n",
      "-0.8312:bullish\n",
      "0.34:bearish\n",
      "0.3252:bearish\n",
      "0.2903:bearish\n",
      "0.7332:bearish\n",
      "-0.8924:bullish\n",
      "-0.7251:bullish\n",
      "-0.277:bullish\n",
      "-0.193:bullish\n",
      "-0.8402:bullish\n",
      "-0.9788:bullish\n",
      "0.9287:bearish\n",
      "-0.9691:bullish\n",
      "-0.7804:bullish\n",
      "-0.1203:bullish\n",
      "0.0516:bearish\n",
      "-0.6908:bullish\n",
      "-0.2204:bullish\n",
      "-0.9617:bullish\n",
      "0.1406:bearish\n",
      "0.8689:bearish\n",
      "-0.2748:bullish\n",
      "0.128:bearish\n",
      "-0.5328:bullish\n",
      "-0.9565:bullish\n",
      "0.0276:bearish\n",
      "-0.4019:bullish\n",
      "0.8625:bearish\n",
      "0.34:bearish\n",
      "0.5859:bearish\n",
      "-0.296:bullish\n",
      "-0.7964:bullish\n",
      "-0.5473:bullish\n",
      "0.9287:bearish\n",
      "-0.2847:bullish\n",
      "0.3278:bearish\n",
      "-0.3378:bullish\n",
      "-0.9355:bullish\n",
      "-0.9294:bullish\n",
      "-0.3086:bullish\n",
      "-0.2023:bullish\n",
      "0.7259:bearish\n",
      "-0.9482:bullish\n",
      "-0.5423:bullish\n",
      "-0.6605:bullish\n",
      "0.6124:bearish\n",
      "0.9508:bearish\n",
      "-0.9704:bullish\n",
      "-0.6808:bullish\n",
      "-0.8374:bullish\n",
      "0.2263:bearish\n",
      "-0.4588:bullish\n",
      "-0.7482:bullish\n",
      "-0.8885:bullish\n",
      "-0.4659:bullish\n",
      "-0.9719:bullish\n",
      "0.2732:bearish\n",
      "-0.3182:bullish\n",
      "0.6124:bearish\n",
      "-0.8056:bullish\n",
      "-0.9349:bullish\n",
      "-0.4818:bullish\n",
      "-0.264:bullish\n",
      "-0.743:bullish\n",
      "-0.4939:bullish\n",
      "0.5574:bearish\n",
      "0.8225:bearish\n",
      "0.3612:bearish\n",
      "-0.7867:bullish\n",
      "-0.7975:bullish\n",
      "-0.2263:bullish\n",
      "-0.6289:bullish\n",
      "0.0516:bearish\n",
      "0.9169:bearish\n",
      "-0.3818:bullish\n",
      "-0.6059:bullish\n",
      "-0.7336:bullish\n",
      "0.932:bearish\n",
      "-0.8043:bullish\n",
      "-0.34:bullish\n",
      "0.9973:bearish\n",
      "0.9167:bearish\n",
      "-0.5574:bullish\n",
      "0.975:bearish\n",
      "0.2815:bearish\n",
      "0.6369:bearish\n",
      "-0.25:bullish\n",
      "-0.1491:bullish\n",
      "0.1901:bearish\n",
      "0.9633:bearish\n",
      "-0.9961:bullish\n",
      "-0.2023:bullish\n",
      "0.5719:bearish\n",
      "-0.8519:bullish\n",
      "0.296:bearish\n",
      "-0.4767:bullish\n",
      "0.4428:bearish\n"
     ]
    }
   ],
   "source": [
    "sir = SentimentIntensityAnalyzer()\n",
    "sent = df.loc[77,'Title'] + ' ' + df.loc[77,'Body']\n",
    "sir.polarity_scores(sent)['compound']\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sent = df.loc[i,'Title'] + ' ' + df.loc[i,'Body']\n",
    "    score = sir.polarity_scores(sent)['compound']\n",
    "    if (score < 0 and df.loc[i, 'Label'] == 'bullish') or (score > 0 and df.loc[i,'Label'] == 'bearish'):\n",
    "        print(str(score) + ':' + df.loc[i, 'Label'])\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "def cleanText(text):\n",
    "    return re.sub(\"http[s]?://\\S+\", ' ', text) #Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-30 00:20:56,669 loading file /home/user/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence(sent)\n",
    "classifier.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf = pd.DataFrame(columns = ['Label', 'Text'])\n",
    "labelDf['Text'] = df['Title'] + ' ' + df['Body']\n",
    "labelDf['Label'] = df['Label']\n",
    "labelDf['Text'] = labelDf['Text'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf['Label'] = '__label__' + labelDf['Label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf = labelDf.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf.iloc[0: int(len(labelDf)*0.8)].to_csv('data/train.csv', sep = '\\t', index = False, header = False)\n",
    "labelDf.iloc[int(len(labelDf)*0.8): int(len(labelDf)*0.9)].to_csv('data/test.csv', sep = '\\t', index = False, header = False)\n",
    "labelDf.iloc[int(len(labelDf)*0.9): ].to_csv('data/dev.csv', sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-30 11:07:11,645 Reading data from data\n",
      "2020-10-30 11:07:11,647 Train: data/train.csv\n",
      "2020-10-30 11:07:11,648 Dev: data/dev.csv\n",
      "2020-10-30 11:07:11,655 Test: data/test.csv\n",
      "2020-10-30 11:07:13,031 Computing label dictionary. Progress:\n",
      "100%|██████████| 971/971 [00:03<00:00, 272.96it/s]2020-10-30 11:07:18,260 [b'bearish', b'bullish', b'neutral']\n",
      "2020-10-30 11:07:18,263 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,271 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-30 11:07:18,288 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,297 Corpus: \"Corpus: 863 train + 108 dev + 108 test sentences\"\n",
      "2020-10-30 11:07:18,306 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,320 Parameters:\n",
      "2020-10-30 11:07:18,323  - learning_rate: \"0.1\"\n",
      "2020-10-30 11:07:18,325  - mini_batch_size: \"32\"\n",
      "2020-10-30 11:07:18,329  - patience: \"3\"\n",
      "2020-10-30 11:07:18,331  - anneal_factor: \"0.5\"\n",
      "2020-10-30 11:07:18,337  - max_epochs: \"10\"\n",
      "2020-10-30 11:07:18,340  - shuffle: \"True\"\n",
      "2020-10-30 11:07:18,342  - train_with_dev: \"False\"\n",
      "2020-10-30 11:07:18,351  - batch_growth_annealing: \"False\"\n",
      "2020-10-30 11:07:18,355 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,359 Model training base path: \"model\"\n",
      "2020-10-30 11:07:18,362 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,365 Device: cpu\n",
      "2020-10-30 11:07:18,368 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 11:07:18,372 Embeddings storage mode: cpu\n",
      "2020-10-30 11:07:18,376 ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "2020-10-30 11:19:27,900 epoch 1 - iter 2/27 - loss 0.86977905 - samples/sec: 0.09 - lr: 0.100000\n",
      "2020-10-30 11:20:27,438 epoch 1 - iter 4/27 - loss 0.92221679 - samples/sec: 1.07 - lr: 0.100000\n",
      "2020-10-30 11:20:52,269 epoch 1 - iter 6/27 - loss 0.87777957 - samples/sec: 2.58 - lr: 0.100000\n",
      "2020-10-30 11:28:59,943 epoch 1 - iter 8/27 - loss 0.89755630 - samples/sec: 0.13 - lr: 0.100000\n",
      "2020-10-30 11:31:12,008 epoch 1 - iter 10/27 - loss 0.90576004 - samples/sec: 0.48 - lr: 0.100000\n",
      "2020-10-30 11:39:36,973 epoch 1 - iter 12/27 - loss 0.89845976 - samples/sec: 0.13 - lr: 0.100000\n",
      "2020-10-30 11:42:52,789 epoch 1 - iter 14/27 - loss 0.91655077 - samples/sec: 0.33 - lr: 0.100000\n",
      "2020-10-30 11:50:54,546 epoch 1 - iter 16/27 - loss 0.90913250 - samples/sec: 0.13 - lr: 0.100000\n",
      "2020-10-30 11:54:17,770 epoch 1 - iter 18/27 - loss 0.90362781 - samples/sec: 0.32 - lr: 0.100000\n",
      "2020-10-30 11:59:27,080 epoch 1 - iter 20/27 - loss 0.91744175 - samples/sec: 0.21 - lr: 0.100000\n",
      "2020-10-30 12:06:05,808 epoch 1 - iter 22/27 - loss 0.91826270 - samples/sec: 0.16 - lr: 0.100000\n",
      "2020-10-30 12:10:48,981 epoch 1 - iter 24/27 - loss 0.91871652 - samples/sec: 0.23 - lr: 0.100000\n",
      "2020-10-30 12:14:33,841 epoch 1 - iter 26/27 - loss 0.92189353 - samples/sec: 0.28 - lr: 0.100000\n",
      "2020-10-30 12:14:40,240 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 12:14:40,245 EPOCH 1 done: loss 0.9202 - lr 0.1000000\n",
      "2020-10-30 12:14:49,726 DEV : loss 0.9797807335853577 - score 0.5648\n",
      "2020-10-30 12:14:51,351 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2020-10-30 12:14:54,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 12:18:36,209 epoch 2 - iter 2/27 - loss 0.79429033 - samples/sec: 0.29 - lr: 0.100000\n",
      "2020-10-30 12:25:03,689 epoch 2 - iter 4/27 - loss 0.81074978 - samples/sec: 0.17 - lr: 0.100000\n",
      "2020-10-30 12:36:43,535 epoch 2 - iter 6/27 - loss 0.85553177 - samples/sec: 0.09 - lr: 0.100000\n",
      "2020-10-30 12:42:26,865 epoch 2 - iter 8/27 - loss 0.83991411 - samples/sec: 0.19 - lr: 0.100000\n",
      "2020-10-30 12:48:13,300 epoch 2 - iter 10/27 - loss 0.83752748 - samples/sec: 0.18 - lr: 0.100000\n",
      "2020-10-30 12:54:00,095 epoch 2 - iter 12/27 - loss 0.87644581 - samples/sec: 0.18 - lr: 0.100000\n",
      "2020-10-30 12:55:58,749 epoch 2 - iter 14/27 - loss 0.88953566 - samples/sec: 0.54 - lr: 0.100000\n",
      "2020-10-30 13:01:18,492 epoch 2 - iter 16/27 - loss 0.87901800 - samples/sec: 0.20 - lr: 0.100000\n",
      "2020-10-30 13:02:43,472 epoch 2 - iter 18/27 - loss 0.86743426 - samples/sec: 0.75 - lr: 0.100000\n",
      "2020-10-30 13:07:52,684 epoch 2 - iter 20/27 - loss 0.85590850 - samples/sec: 0.21 - lr: 0.100000\n",
      "2020-10-30 13:13:51,747 epoch 2 - iter 22/27 - loss 0.85722169 - samples/sec: 0.18 - lr: 0.100000\n",
      "2020-10-30 13:15:47,421 epoch 2 - iter 24/27 - loss 0.87331782 - samples/sec: 0.55 - lr: 0.100000\n",
      "2020-10-30 13:22:22,982 epoch 2 - iter 26/27 - loss 0.87235689 - samples/sec: 0.16 - lr: 0.100000\n",
      "2020-10-30 13:24:50,096 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 13:24:50,135 EPOCH 2 done: loss 0.8691 - lr 0.1000000\n",
      "2020-10-30 13:24:58,973 DEV : loss 0.9862983822822571 - score 0.5648\n",
      "2020-10-30 13:25:00,283 BAD EPOCHS (no improvement): 1\n",
      "2020-10-30 13:25:00,285 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-30 13:29:24,695 epoch 3 - iter 2/27 - loss 0.94070512 - samples/sec: 0.24 - lr: 0.100000\n"
     ]
    }
   ],
   "source": [
    "'''from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "corpus = ClassificationCorpus(Path('data/'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove')]\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('model/', max_epochs=10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-30 13:33:38,378 loading file model/best-model.pt\n",
      "[bullish (0.5738)]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('model/best-model.pt')\n",
    "sentence = Sentence('stonks going up')\n",
    "classifier.predict(sentence)\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}