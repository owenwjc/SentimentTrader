{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee30a202add5215adcbb767012aec8477a9c484e522cef3494d0f72d70b8c03"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/user/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.db\n",
    "threads = db.threads\n",
    "companies = db.companylist\n",
    "matches = db.matches\n",
    "chunks = db.chunks\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "df = pd.DataFrame.from_records(threads.find({'Label':{'$ne': 0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.9077:bullish\n",
      "-0.7453:bullish\n",
      "-0.4522:bullish\n",
      "-0.9222:bullish\n",
      "0.9274:bearish\n",
      "0.8258:bearish\n",
      "0.1027:bearish\n",
      "-0.6037:bullish\n",
      "-0.9495:bullish\n",
      "0.8022:bearish\n",
      "-0.5267:bullish\n",
      "-0.5994:bullish\n",
      "0.3716:bearish\n",
      "0.8689:bearish\n",
      "-0.743:bullish\n",
      "0.4791:bearish\n",
      "-0.608:bullish\n",
      "0.2263:bearish\n",
      "-0.8371:bullish\n",
      "-0.8185:bullish\n",
      "0.6326:bearish\n",
      "0.9801:bearish\n",
      "-0.0874:bullish\n",
      "-0.953:bullish\n",
      "-0.25:bullish\n",
      "-0.5574:bullish\n",
      "0.5978:bearish\n",
      "0.9976:bearish\n",
      "-0.8658:bullish\n",
      "-0.4246:bullish\n",
      "-0.9578:bullish\n",
      "-0.3182:bullish\n",
      "-0.1027:bullish\n",
      "-0.5829:bullish\n",
      "-0.2313:bullish\n",
      "-0.8578:bullish\n",
      "0.7506:bearish\n",
      "0.7063:bearish\n",
      "-0.5789:bullish\n",
      "-0.4939:bullish\n",
      "0.8266:bearish\n",
      "-0.3533:bullish\n",
      "-0.4767:bullish\n",
      "-0.3249:bullish\n",
      "-0.1927:bullish\n",
      "0.4404:bearish\n",
      "0.323:bearish\n",
      "-0.7814:bullish\n",
      "0.296:bearish\n",
      "-0.7025:bullish\n",
      "0.9917:bearish\n",
      "-0.5106:bullish\n",
      "-0.599:bullish\n",
      "0.8943:bearish\n",
      "0.8957:bearish\n",
      "-0.6369:bullish\n",
      "0.9042:bearish\n",
      "-0.5106:bullish\n",
      "0.8236:bearish\n",
      "0.9208:bearish\n",
      "-0.1027:bullish\n",
      "0.6739:bearish\n",
      "0.9169:bearish\n",
      "-0.3972:bullish\n",
      "-0.1655:bullish\n",
      "0.9617:bearish\n",
      "0.9661:bearish\n",
      "0.8656:bearish\n",
      "0.9984:bearish\n",
      "-0.0891:bullish\n",
      "0.9245:bearish\n",
      "0.2263:bearish\n",
      "-0.7184:bullish\n",
      "-0.128:bullish\n",
      "0.7906:bearish\n",
      "0.5766:bearish\n",
      "0.2103:bearish\n",
      "0.5789:bearish\n",
      "-0.0772:bullish\n",
      "0.7646:bearish\n",
      "-0.657:bullish\n",
      "0.9724:bearish\n",
      "-0.2429:bullish\n",
      "0.4824:bearish\n",
      "-0.1027:bullish\n",
      "0.7964:bearish\n",
      "0.9653:bearish\n",
      "-0.8537:bullish\n",
      "-0.1779:bullish\n",
      "-0.8856:bullish\n",
      "-0.2732:bullish\n",
      "-0.9059:bullish\n",
      "-0.1154:bullish\n",
      "0.8247:bearish\n",
      "-0.5346:bullish\n",
      "0.9442:bearish\n",
      "0.9635:bearish\n",
      "-0.128:bullish\n",
      "-0.4005:bullish\n",
      "0.5106:bearish\n",
      "-0.7115:bullish\n",
      "-0.4636:bullish\n",
      "-0.4309:bullish\n",
      "0.993:bearish\n",
      "0.3612:bearish\n",
      "-0.9873:bullish\n",
      "-0.7184:bullish\n",
      "-0.3551:bullish\n",
      "0.7213:bearish\n",
      "-0.2023:bullish\n",
      "-0.1531:bullish\n",
      "0.9122:bearish\n",
      "-0.8932:bullish\n",
      "-0.2356:bullish\n",
      "-0.9001:bullish\n",
      "-0.5216:bullish\n",
      "-0.5023:bullish\n",
      "0.2263:bearish\n",
      "-0.2744:bullish\n",
      "-0.4588:bullish\n",
      "-0.226:bullish\n",
      "-0.0516:bullish\n",
      "-0.8126:bullish\n",
      "-0.967:bullish\n",
      "0.3182:bearish\n",
      "-0.6597:bullish\n",
      "0.7227:bearish\n",
      "0.9569:bearish\n",
      "-0.8312:bullish\n",
      "0.34:bearish\n",
      "0.3252:bearish\n",
      "0.2903:bearish\n",
      "0.7332:bearish\n",
      "-0.8924:bullish\n",
      "-0.7251:bullish\n",
      "-0.277:bullish\n",
      "-0.193:bullish\n",
      "-0.8402:bullish\n",
      "-0.9788:bullish\n",
      "0.9287:bearish\n",
      "-0.9691:bullish\n",
      "-0.7804:bullish\n",
      "-0.1203:bullish\n",
      "0.0516:bearish\n",
      "-0.6908:bullish\n",
      "-0.2204:bullish\n",
      "-0.9617:bullish\n",
      "0.1406:bearish\n",
      "0.8689:bearish\n",
      "-0.2748:bullish\n",
      "0.128:bearish\n",
      "-0.5328:bullish\n",
      "-0.9565:bullish\n",
      "0.0276:bearish\n",
      "-0.4019:bullish\n",
      "0.8625:bearish\n",
      "0.34:bearish\n",
      "0.5859:bearish\n",
      "-0.296:bullish\n",
      "-0.7964:bullish\n",
      "-0.5473:bullish\n",
      "0.9287:bearish\n",
      "-0.2847:bullish\n",
      "0.3278:bearish\n",
      "-0.3378:bullish\n",
      "-0.9355:bullish\n",
      "-0.9294:bullish\n",
      "-0.3086:bullish\n",
      "-0.2023:bullish\n",
      "0.7259:bearish\n",
      "-0.9482:bullish\n",
      "-0.5423:bullish\n",
      "-0.6605:bullish\n",
      "0.6124:bearish\n",
      "0.9508:bearish\n",
      "-0.9704:bullish\n",
      "-0.6808:bullish\n",
      "-0.8374:bullish\n",
      "0.2263:bearish\n",
      "-0.4588:bullish\n",
      "-0.7482:bullish\n",
      "-0.8885:bullish\n",
      "-0.4659:bullish\n",
      "-0.9719:bullish\n",
      "0.2732:bearish\n",
      "-0.3182:bullish\n",
      "0.6124:bearish\n",
      "-0.8056:bullish\n",
      "-0.9349:bullish\n",
      "-0.4818:bullish\n",
      "-0.264:bullish\n",
      "-0.743:bullish\n",
      "-0.4939:bullish\n",
      "0.5574:bearish\n",
      "0.8225:bearish\n",
      "0.3612:bearish\n",
      "-0.7867:bullish\n",
      "-0.7975:bullish\n",
      "-0.2263:bullish\n",
      "-0.6289:bullish\n",
      "0.0516:bearish\n",
      "0.9169:bearish\n",
      "-0.3818:bullish\n",
      "-0.6059:bullish\n",
      "-0.7336:bullish\n",
      "0.932:bearish\n",
      "-0.8043:bullish\n",
      "-0.34:bullish\n",
      "0.9973:bearish\n",
      "0.9167:bearish\n",
      "-0.5574:bullish\n",
      "0.975:bearish\n",
      "0.2815:bearish\n",
      "0.6369:bearish\n",
      "-0.25:bullish\n",
      "-0.1491:bullish\n",
      "0.1901:bearish\n",
      "0.9633:bearish\n",
      "-0.9961:bullish\n",
      "-0.2023:bullish\n",
      "0.5719:bearish\n",
      "-0.8519:bullish\n",
      "0.296:bearish\n",
      "-0.4767:bullish\n",
      "0.4428:bearish\n"
     ]
    }
   ],
   "source": [
    "sir = SentimentIntensityAnalyzer()\n",
    "sent = df.loc[77,'Title'] + ' ' + df.loc[77,'Body']\n",
    "sir.polarity_scores(sent)['compound']\n",
    "count = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sent = df.loc[i,'Title'] + ' ' + df.loc[i,'Body']\n",
    "    score = sir.polarity_scores(sent)['compound']\n",
    "    if (score < 0 and df.loc[i, 'Label'] == 'bullish') or (score > 0 and df.loc[i,'Label'] == 'bearish'):\n",
    "        print(str(score) + ':' + df.loc[i, 'Label'])\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "def cleanText(text):\n",
    "    return re.sub(\"http[s]?://\\S+\", ' ', text) #Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-29 21:27:11,966 loading file /home/user/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentence = Sentence(sent)\n",
    "classifier.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf = pd.DataFrame(columns = ['Label', 'Text'])\n",
    "labelDf['Text'] = df['Title'] + ' ' + df['Body']\n",
    "labelDf['Label'] = df['Label']\n",
    "labelDf['Text'] = labelDf['Text'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf['Label'] = '__label__' + labelDf['Label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf = labelDf.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf.iloc[0: int(len(labelDf)*0.8)].to_csv('train.csv', sep = '\\t', index = False, header = False)\n",
    "labelDf.iloc[int(len(labelDf)*0.8): int(len(labelDf)*0.9)].to_csv('test.csv', sep = '\\t', index = False, header = False)\n",
    "labelDf.iloc[int(len(labelDf)*0.9): ].to_csv('dev.csv', sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-10-29 21:27:14,220 Reading data from .\n",
      "2020-10-29 21:27:14,222 Train: train.csv\n",
      "2020-10-29 21:27:14,226 Dev: dev.csv\n",
      "2020-10-29 21:27:14,229 Test: test.csv\n",
      "2020-10-29 21:27:16,153 Computing label dictionary. Progress:\n",
      "100%|██████████| 971/971 [00:06<00:00, 158.21it/s]2020-10-29 21:27:23,515 [b'neutral', b'bullish', b'bearish']\n",
      "\n",
      "2020-10-29 21:27:23,556 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,558 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentLSTMEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-10-29 21:27:23,562 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,565 Corpus: \"Corpus: 863 train + 108 dev + 108 test sentences\"\n",
      "2020-10-29 21:27:23,566 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,570 Parameters:\n",
      "2020-10-29 21:27:23,571  - learning_rate: \"0.1\"\n",
      "2020-10-29 21:27:23,572  - mini_batch_size: \"32\"\n",
      "2020-10-29 21:27:23,575  - patience: \"3\"\n",
      "2020-10-29 21:27:23,581  - anneal_factor: \"0.5\"\n",
      "2020-10-29 21:27:23,583  - max_epochs: \"10\"\n",
      "2020-10-29 21:27:23,584  - shuffle: \"True\"\n",
      "2020-10-29 21:27:23,586  - train_with_dev: \"False\"\n",
      "2020-10-29 21:27:23,588  - batch_growth_annealing: \"False\"\n",
      "2020-10-29 21:27:23,589 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,591 Model training base path: \".\"\n",
      "2020-10-29 21:27:23,595 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,596 Device: cpu\n",
      "2020-10-29 21:27:23,597 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:27:23,599 Embeddings storage mode: cpu\n",
      "2020-10-29 21:27:23,602 ----------------------------------------------------------------------------------------------------\n",
      "2020-10-29 21:36:09,739 epoch 1 - iter 2/27 - loss 0.99053448 - samples/sec: 0.12 - lr: 0.100000\n",
      "2020-10-29 21:41:56,124 epoch 1 - iter 4/27 - loss 0.95274965 - samples/sec: 0.18 - lr: 0.100000\n",
      "2020-10-29 21:46:39,814 epoch 1 - iter 6/27 - loss 0.96748035 - samples/sec: 0.23 - lr: 0.100000\n",
      "Process Process-12:\n",
      "Process Process-13:\n",
      "Process Process-10:\n",
      "Process Process-14:\n",
      "Process Process-11:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/anaconda3/envs/vsenv/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "corpus = ClassificationCorpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
    "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}