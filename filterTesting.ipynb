{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('vsenv': conda)",
   "display_name": "Python 3.8.5 64-bit ('vsenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1ee30a202add5215adcbb767012aec8477a9c484e522cef3494d0f72d70b8c03"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.db\n",
    "threads = db.threads\n",
    "companies = db.companylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(threads.find({'Label' :{'$ne': 0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent = df['Body'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text):\n",
    "    chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    for i in chunked:\n",
    "        if type(i) == nltk.tree.Tree and i.label() == 'ORGANIZATION':\n",
    "            current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = get_continuous_chunks(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hopefully my name isn t too biased here. But I will reiterate what people talk about any time AMD is mentioned in the past two months. 1 AMD s CPU leaked yesterday. And to say the least it looks promising. Article below as I will not go into depth on this. In summary Intel has had a better CPU for years but this looks like its changing. If priced similarly to previous CPU s AMD will no doubt be the leader in this price range. https //www.techradar.com/news/amd ryzen 7 5800x leak shows a powerhouse gaming cpu that could embarrass intels core i9 10900k 2 AMD/NVIDIA battle. For a long time NVIDIA has been the leader in the GPU battle. With the horrid launch of the 30xx series and recent leaks about AMD s GPU price to performance its looking more and more like AMD will take market share from NVIDIA. Many retailers report not even getting 3000 series cards Huge driver issues making games unplayable Scalpers/bots taking all the available cards and reselling 3 AMD is selling both XBOX and PS5 their Zen and RDNA chips. There is no other competition and production numbers are being met. https //www.pocket lint.com/laptops/news/playstation/153151 amd chips xbox series x playstation 5 ps5 schedule 4 Lisa Su AMD CEO . This summary below linked by u/Souskei about how she revived AMD is why I personally have so much faith in the company. https //medium.com/ jyjayy94/dr lisa su the living legend of amd 7e0173d3a4a4 IMPORTANT DATES AMD ZEN 3 reveal October 8th AMD GPU reveal October 28th AMD earnings announcement November 3rd expected $.31 compared to $.14 for last year same quarter https //www.tomshardware.com/news/amd announces keynote dates for zen 3 and big navi The next month is one of the most important months AMD has had in years. I am fully expecting them to crush it and finally be on Intel/Nvidia s level after years of playing catch up. We don t need to bring up previous AMD driver issues My recommendations for options Full disclaimer. I am in for 20 Nov 90C. Now let s look at Bid/ask spreads volume and the greeks below. I will only look at option chains expiring after November due to all the announcements in October. 6 Nov is not worth it for reasons below. the average bid/ask spread is 40 cents for OTM/ITM calls. Personally I usually buy close ITM calls for the delta/theta movement as it is safer. Theta for closer OTM calls are already at .11 Delta is hovering at about .5 which is okay but preferably since its a month away we would want it a little more. No doubt it will move up as AMD increases. But so will Theta for an option expiring a week after the announcements. 20 Nov My position of choice due to much smaller bid/ask because I m not a fan of losing money to MM s. Theta of .6/.7 right now which buys us more time. Since I plan on selling the options during early November I still have adequate time to not get wrecked by theta and let delta move in my favor. 15 Jan 21 Another recommendation of mine. Earnings will be about to be fully reported. VOL will be high and so will the expectations. The play is up to you here. But i recommend anything over $95 at minimum.'"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "my_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "companydf = pd.DataFrame.from_records(companies.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                           10x Genomics, Inc.\n",
       "1       1347 Property Insurance Holdings, Inc.\n",
       "2       1347 Property Insurance Holdings, Inc.\n",
       "3                     180 Degree Capital Corp.\n",
       "4                      1-800-FLOWERS.COM, Inc.\n",
       "                         ...                  \n",
       "5716                               Zumiez Inc.\n",
       "5717                            Zymeworks Inc.\n",
       "5718             Zynerba Pharmaceuticals, Inc.\n",
       "5719                               Zynex, Inc.\n",
       "5720                                Zynga Inc.\n",
       "Name: Name, Length: 5721, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "companydf['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    string = re.sub(r'[,-./]|\\sBD',r'', string)\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "company_names = companydf['Name']\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(company_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SELFTIMED: 0.23461389541625977\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.8)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      left_side  \\\n",
       "266         AllianzGI Convertible & Income Fund   \n",
       "286  AllianzGI Equity & Convertible Income Fund   \n",
       "32        Aberdeen Global Dynamic Dividend Fund   \n",
       "381                        Ameri Holdings, Inc.   \n",
       "276      AllianzGI Convertible & Income Fund II   \n",
       "727           ARYA Sciences Acquisition Corp II   \n",
       "221                    Akero Therapeutics, Inc.   \n",
       "378                        Ameri Holdings, Inc.   \n",
       "38         Aberdeen Total Dynamic Dividend Fund   \n",
       "281      AllianzGI Convertible & Income Fund II   \n",
       "272         AllianzGI Convertible & Income Fund   \n",
       "271         AllianzGI Convertible & Income Fund   \n",
       "737          ARYA Sciences Acquisition Corp III   \n",
       "738          ARYA Sciences Acquisition Corp III   \n",
       "456              American Resources Corporation   \n",
       "285  AllianzGI Equity & Convertible Income Fund   \n",
       "277      AllianzGI Convertible & Income Fund II   \n",
       "735           ARYA Sciences Acquisition Corp II   \n",
       "731           ARYA Sciences Acquisition Corp II   \n",
       "280      AllianzGI Convertible & Income Fund II   \n",
       "\n",
       "                                 right_side  similairity  \n",
       "266  AllianzGI Convertible & Income Fund II     0.968951  \n",
       "286     AllianzGI Convertible & Income Fund     0.800869  \n",
       "32     Aberdeen Total Dynamic Dividend Fund     0.849906  \n",
       "381                     Everi Holdings Inc.     0.810480  \n",
       "276     AllianzGI Convertible & Income Fund     0.968951  \n",
       "727      ARYA Sciences Acquisition Corp III     0.969687  \n",
       "221                Spero Therapeutics, Inc.     0.804962  \n",
       "378                     Everi Holdings Inc.     0.810480  \n",
       "38    Aberdeen Global Dynamic Dividend Fund     0.849906  \n",
       "281     AllianzGI Convertible & Income Fund     0.968951  \n",
       "272  AllianzGI Convertible & Income Fund II     0.968951  \n",
       "271  AllianzGI Convertible & Income Fund II     0.968951  \n",
       "737       ARYA Sciences Acquisition Corp II     0.969687  \n",
       "738       ARYA Sciences Acquisition Corp II     0.969687  \n",
       "456      REX American Resources Corporation     0.836362  \n",
       "285     AllianzGI Convertible & Income Fund     0.800869  \n",
       "277     AllianzGI Convertible & Income Fund     0.968951  \n",
       "735      ARYA Sciences Acquisition Corp III     0.969687  \n",
       "731      ARYA Sciences Acquisition Corp III     0.969687  \n",
       "280     AllianzGI Convertible & Income Fund     0.968951  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_side</th>\n      <th>right_side</th>\n      <th>similairity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>266</th>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>286</th>\n      <td>AllianzGI Equity &amp; Convertible Income Fund</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.800869</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Aberdeen Global Dynamic Dividend Fund</td>\n      <td>Aberdeen Total Dynamic Dividend Fund</td>\n      <td>0.849906</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>Ameri Holdings, Inc.</td>\n      <td>Everi Holdings Inc.</td>\n      <td>0.810480</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>727</th>\n      <td>ARYA Sciences Acquisition Corp II</td>\n      <td>ARYA Sciences Acquisition Corp III</td>\n      <td>0.969687</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>Akero Therapeutics, Inc.</td>\n      <td>Spero Therapeutics, Inc.</td>\n      <td>0.804962</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>Ameri Holdings, Inc.</td>\n      <td>Everi Holdings Inc.</td>\n      <td>0.810480</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Aberdeen Total Dynamic Dividend Fund</td>\n      <td>Aberdeen Global Dynamic Dividend Fund</td>\n      <td>0.849906</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>737</th>\n      <td>ARYA Sciences Acquisition Corp III</td>\n      <td>ARYA Sciences Acquisition Corp II</td>\n      <td>0.969687</td>\n    </tr>\n    <tr>\n      <th>738</th>\n      <td>ARYA Sciences Acquisition Corp III</td>\n      <td>ARYA Sciences Acquisition Corp II</td>\n      <td>0.969687</td>\n    </tr>\n    <tr>\n      <th>456</th>\n      <td>American Resources Corporation</td>\n      <td>REX American Resources Corporation</td>\n      <td>0.836362</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>AllianzGI Equity &amp; Convertible Income Fund</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.800869</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.968951</td>\n    </tr>\n    <tr>\n      <th>735</th>\n      <td>ARYA Sciences Acquisition Corp II</td>\n      <td>ARYA Sciences Acquisition Corp III</td>\n      <td>0.969687</td>\n    </tr>\n    <tr>\n      <th>731</th>\n      <td>ARYA Sciences Acquisition Corp II</td>\n      <td>ARYA Sciences Acquisition Corp III</td>\n      <td>0.969687</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>AllianzGI Convertible &amp; Income Fund II</td>\n      <td>AllianzGI Convertible &amp; Income Fund</td>\n      <td>0.968951</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "matches_df = get_matches_df(matches, company_names, top = 1000)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}