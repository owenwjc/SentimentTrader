{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "source": [
    "# Pulling stock tickers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContinuousChunks(text):\n",
    "    chunked = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)))\n",
    "    continuousChunkdf = pd.DataFrame(columns = ['id', 'Named Entity', 'Label'])\n",
    "    currentChunk = []\n",
    "    currentLabel = []\n",
    "    for i in chunked:\n",
    "        if type(i) == nltk.tree.Tree:\n",
    "            currentChunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            currentLabel.append(i.label())\n",
    "        if currentChunk:\n",
    "            namedEntity = \" \".join(currentChunk)\n",
    "            label = \" \".join(currentLabel)\n",
    "            if namedEntity not in continuousChunkdf['Named Entity']:\n",
    "                d = {'id': 0, 'Named Entity': namedEntity, 'Label': label}\n",
    "                continuousChunkdf = continuousChunkdf.append(d, ignore_index = True)\n",
    "                currentChunk = []\n",
    "                currentLabel = []\n",
    "        else:\n",
    "            continue\n",
    "    return continuousChunkdf\n",
    "\n",
    "def mapResults(result, leftNames, rightNames, threadID, threshold):\n",
    "    result[result < threshold] = 0\n",
    "    matchdf = pd.DataFrame(0, index = np.arange(len(result.nonzero()[0])), columns = ['id','Left', 'Right', 'Similarity'])\n",
    "    for i in range(len(result.nonzero()[0])):\n",
    "        matchdf.loc[i, 'Left'] = leftNames[result.nonzero()[0][i]]\n",
    "        matchdf.loc[i, 'Right'] = rightNames[result.nonzero()[1][i]]\n",
    "        matchdf.loc[i, 'Similarity'] = result[result.nonzero()[0][i]][result.nonzero()[1][i]]\n",
    "    matchdf['id'] = threadID\n",
    "    return matchdf.drop_duplicates(subset = 'Right')\n",
    "\n",
    "def pullTickers(string):\n",
    "    dollarTicker = set(re.findall(r\"\\$\\b[A-Z]{1,4}\\b\",string))\n",
    "    manualTicker = re.findall(r\"\\b[A-Z]{2,4}\\b\",string)\n",
    "    manualTicker = list(set(manualTicker).difference(notTickers))\n",
    "    manualTicker = set(['$' + manualTicker for manualTicker in manualTicker])\n",
    "    combined = manualTicker.union(dollarTicker)\n",
    "    return combined.intersection(companydf['Manual'])\n",
    "\n",
    "notTickers = {'DCF', 'IMO', 'CAN', 'MMS', 'ARE', 'CDC', 'NEW', 'LOVE', 'NYC', 'CASH', 'AI', \n",
    "'NAV', 'GOOD', 'DD', 'ATH', 'APPS', 'EDIT', 'WOW', 'PCB', 'UNIT', 'TA', 'VG', 'SELF', 'MR',\n",
    "'RARE', 'ALEX', 'KEY', 'STIM', 'GO', 'SEE', 'CFO', 'CAL', 'REV', 'PE', 'CHI', 'EVE', 'PDT',\n",
    "'CO', 'EV', 'TTM', 'EOD', 'AT', 'HUGE', 'ES', 'ONE', 'PT', 'CEO', 'ZEN', 'NOW', 'JAN', 'O',\n",
    "'OR', 'PG', 'ROCK', 'FOUR', 'ONE', 'TWO', 'FIVE', 'SIX', 'NINE', 'TEN', 'ON', 'SU', 'XT',\n",
    "'WELL', 'NOV', 'MAR', 'JAN', 'FUN', 'NOW', 'VERY', 'USA', 'POST'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client.db\n",
    "comments = db.comments\n",
    "companies = db.companylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companydf = pd.DataFrame.from_records(companies.find())\n",
    "commentdf = pd.DataFrame.from_records(comments.find({'created_utc': {'$exists': 'true'}, 'sentiment': {'$exists': 'false'}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentdf['sentiment'] = 0\n",
    "commentdf['stocks'] = 0\n",
    "commentdf['stocks'] = commentdf['stocks'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStrings(string):\n",
    "    return re.sub(\"[^a-zA-Z0-9./$:,'&]+\", ' ',string) #only include normal string characters\n",
    "def cleanText(text):\n",
    "    return re.sub(\"http[s]?://\\S+\", ' ', text) #Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentdf['body'] = commentdf['body'].apply(cleanStrings)\n",
    "commentdf['body'] = commentdf['body'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyNames = companydf['Name'].unique()\n",
    "companySymbols = companydf['Symbol'].unique()\n",
    "nameVectorizer = TfidfVectorizer(min_df = 1)\n",
    "symbolVectorizer = TfidfVectorizer(min_df = 1)\n",
    "companyMatrix = nameVectorizer.fit_transform(companyNames)\n",
    "symbolMatrix = symbolVectorizer.fit_transform(companySymbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(commentdf['body'])):\n",
    "    sent = commentdf['body'][i]\n",
    "    threadID = i\n",
    "    chunks = getContinuousChunks(sent)\n",
    "    chunkdf = chunks.loc[(chunks['Label'] == 'ORGANIZATION') | (chunks['Label'] == 'PERSON')].reset_index()\n",
    "    stocklist = []\n",
    "\n",
    "    if len(chunkdf['Label']) > 0:\n",
    "        nerNameMatrix = nameVectorizer.transform(chunkdf['Named Entity'])\n",
    "        nerSymbolMatrix = symbolVectorizer.transform(chunkdf['Named Entity'])\n",
    "        nameResult = cosine_similarity(nerNameMatrix, companyMatrix)\n",
    "        symbolResult = cosine_similarity(nerSymbolMatrix, symbolMatrix)\n",
    "        namedf = mapResults(nameResult, chunkdf['Named Entity'], companyNames, threadID, 0.85)\n",
    "        symboldf = mapResults(symbolResult, chunkdf['Named Entity'], companySymbols, threadID, 1)\n",
    "        stocklist = list(set(namedf.loc[namedf['Similarity'] > 0.8, 'Right'].append(symboldf.loc[symboldf['Similarity'] > 0.999, 'Right'])))\n",
    "    commentdf.at[threadID, 'stocks'] = stocklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[list(set(a).union(b)) for a,b in commentdf['body'].apply(pullTickers), commentdf['stocks'])] # TODO"
   ]
  },
  {
   "source": [
    "# Sentiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('model/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(\"drill team six\")\n",
    "classifier.predict(sentence)\n",
    "sentence.labels[0].to_dict()"
   ]
  },
  {
   "source": [
    "# Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}